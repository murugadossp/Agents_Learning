{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/murugadossp/Agents_Learning/blob/main/LLM_Function_Calling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!!pip install litellm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ak0TPDGxQ6rB",
        "outputId": "33a3f58e-a5a2-4881-8f9d-338fb6f86766"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Collecting litellm',\n",
              " '  Downloading litellm-1.71.1-py3-none-any.whl.metadata (38 kB)',\n",
              " 'Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from litellm) (3.11.15)',\n",
              " 'Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from litellm) (8.2.0)',\n",
              " 'Requirement already satisfied: httpx>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from litellm) (0.28.1)',\n",
              " 'Collecting httpx-aiohttp>=0.1.4 (from litellm)',\n",
              " '  Downloading httpx_aiohttp-0.1.4-py3-none-any.whl.metadata (4.5 kB)',\n",
              " 'Requirement already satisfied: importlib-metadata>=6.8.0 in /usr/local/lib/python3.11/dist-packages (from litellm) (8.7.0)',\n",
              " 'Requirement already satisfied: jinja2<4.0.0,>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from litellm) (3.1.6)',\n",
              " 'Requirement already satisfied: jsonschema<5.0.0,>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from litellm) (4.23.0)',\n",
              " 'Requirement already satisfied: openai>=1.68.2 in /usr/local/lib/python3.11/dist-packages (from litellm) (1.78.1)',\n",
              " 'Requirement already satisfied: pydantic<3.0.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from litellm) (2.11.4)',\n",
              " 'Collecting python-dotenv>=0.2.0 (from litellm)',\n",
              " '  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)',\n",
              " 'Requirement already satisfied: tiktoken>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from litellm) (0.9.0)',\n",
              " 'Requirement already satisfied: tokenizers in /usr/local/lib/python3.11/dist-packages (from litellm) (0.21.1)',\n",
              " 'Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.23.0->litellm) (4.9.0)',\n",
              " 'Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.23.0->litellm) (2025.4.26)',\n",
              " 'Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.23.0->litellm) (1.0.9)',\n",
              " 'Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.23.0->litellm) (3.10)',\n",
              " 'Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.23.0->litellm) (0.16.0)',\n",
              " 'Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->litellm) (2.6.1)',\n",
              " 'Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->litellm) (1.3.2)',\n",
              " 'Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->litellm) (25.3.0)',\n",
              " 'Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->litellm) (1.6.0)',\n",
              " 'Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->litellm) (6.4.3)',\n",
              " 'Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->litellm) (0.3.1)',\n",
              " 'Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->litellm) (1.20.0)',\n",
              " 'Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata>=6.8.0->litellm) (3.21.0)',\n",
              " 'Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2<4.0.0,>=3.1.2->litellm) (3.0.2)',\n",
              " 'Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm) (2025.4.1)',\n",
              " 'Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm) (0.36.2)',\n",
              " 'Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm) (0.24.0)',\n",
              " 'Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.68.2->litellm) (1.9.0)',\n",
              " 'Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.68.2->litellm) (0.9.0)',\n",
              " 'Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai>=1.68.2->litellm) (1.3.1)',\n",
              " 'Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai>=1.68.2->litellm) (4.67.1)',\n",
              " 'Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai>=1.68.2->litellm) (4.13.2)',\n",
              " 'Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.0.0->litellm) (0.7.0)',\n",
              " 'Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.0.0->litellm) (2.33.2)',\n",
              " 'Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.0.0->litellm) (0.4.0)',\n",
              " 'Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken>=0.7.0->litellm) (2024.11.6)',\n",
              " 'Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken>=0.7.0->litellm) (2.32.3)',\n",
              " 'Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers->litellm) (0.31.2)',\n",
              " 'Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm) (3.18.0)',\n",
              " 'Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm) (2025.3.2)',\n",
              " 'Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm) (24.2)',\n",
              " 'Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm) (6.0.2)',\n",
              " 'Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken>=0.7.0->litellm) (3.4.2)',\n",
              " 'Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken>=0.7.0->litellm) (2.4.0)',\n",
              " 'Downloading litellm-1.71.1-py3-none-any.whl (7.9 MB)',\n",
              " '\\x1b[?25l   \\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m0.0/7.9 MB\\x1b[0m \\x1b[31m?\\x1b[0m eta \\x1b[36m-:--:--\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m0.6/7.9 MB\\x1b[0m \\x1b[31m19.6 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m3.3/7.9 MB\\x1b[0m \\x1b[31m47.1 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━\\x1b[0m \\x1b[32m6.6/7.9 MB\\x1b[0m \\x1b[31m62.0 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m \\x1b[32m7.9/7.9 MB\\x1b[0m \\x1b[31m64.8 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m7.9/7.9 MB\\x1b[0m \\x1b[31m44.2 MB/s\\x1b[0m eta \\x1b[36m0:00:00\\x1b[0m',\n",
              " '\\x1b[?25hDownloading httpx_aiohttp-0.1.4-py3-none-any.whl (5.0 kB)',\n",
              " 'Downloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)',\n",
              " 'Installing collected packages: python-dotenv, httpx-aiohttp, litellm',\n",
              " 'Successfully installed httpx-aiohttp-0.1.4 litellm-1.71.1 python-dotenv-1.1.0']"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Important!!!\n",
        "#\n",
        "# <---- Set your 'OPENAI_API_KEY' as a secret over there with the \"key\" icon\n",
        "#\n",
        "#\n",
        "import os\n",
        "from google.colab import userdata\n",
        "api_key = userdata.get('OPENAI_API_KEY')\n",
        "os.environ['OPENAI_API_KEY'] = api_key"
      ],
      "metadata": {
        "id": "KEYrzG2vB8Ip"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "from typing import List\n",
        "\n",
        "from litellm import completion"
      ],
      "metadata": {
        "id": "keSzPC_tRD82"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def list_files() -> List[str]:\n",
        "    \"\"\"List files in the current directory.\"\"\"\n",
        "    return os.listdir(\".\")\n",
        "\n",
        "def read_file(file_name: str) -> str:\n",
        "    \"\"\"Read a file's contents.\"\"\"\n",
        "    try:\n",
        "        with open(file_name, \"r\") as file:\n",
        "            return file.read()\n",
        "    except FileNotFoundError:\n",
        "        return f\"Error: {file_name} not found.\"\n",
        "    except Exception as e:\n",
        "        return f\"Error: {str(e)}\"\n",
        "\n",
        "def terminate(message: str) -> None:\n",
        "    \"\"\"Terminate the agent loop and provide a summary message.\"\"\"\n",
        "    print(f\"Termination message: {message}\")"
      ],
      "metadata": {
        "id": "_3RUt6HMRIvm"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tool_functions = {\n",
        "    \"list_files\": list_files,\n",
        "    \"read_file\": read_file,\n",
        "    \"terminate\": terminate\n",
        "}"
      ],
      "metadata": {
        "id": "_tc5FAd1RLiZ"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tools = [\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"list_files\",\n",
        "            \"description\": \"Returns a list of files in the directory.\",\n",
        "            \"parameters\": {\"type\": \"object\", \"properties\": {}, \"required\": []}\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"read_file\",\n",
        "            \"description\": \"Reads the content of a specified file in the directory.\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\"file_name\": {\"type\": \"string\"}},\n",
        "                \"required\": [\"file_name\"]\n",
        "            }\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"terminate\",\n",
        "            \"description\": \"Terminates the conversation. No further actions or interactions are possible after this. Prints the provided message for the user.\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"message\": {\"type\": \"string\"},\n",
        "                },\n",
        "                \"required\": [\"message\"]\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "]"
      ],
      "metadata": {
        "id": "nNHJ5-aeRS3Q"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Our rules are simplified since we don't have to worry about getting a specific output format\n",
        "agent_rules = [{\n",
        "    \"role\": \"system\",\n",
        "    \"content\": \"\"\"\n",
        "You are an AI agent that can perform tasks by using available tools.\n",
        "\n",
        "If a user asks about files, documents, or content, first list the files before reading them.\n",
        "\n",
        "When you are done, terminate the conversation by using the \"terminate\" tool and I will provide the results to the user.\n",
        "\"\"\"\n",
        "}]"
      ],
      "metadata": {
        "id": "bJBF6rQ1RUtX"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "Mwe2eeOQB0cC"
      },
      "outputs": [],
      "source": [
        "def user_task():\n",
        "\n",
        "  # Initialize agent parameters\n",
        "  iterations = 1\n",
        "  max_iterations = 10\n",
        "\n",
        "  user_task = input(\"What would you like me to do? \")\n",
        "\n",
        "  memory = [{\"role\": \"user\", \"content\": user_task}]\n",
        "\n",
        "  # The Agent Loop\n",
        "  while iterations <= max_iterations:\n",
        "\n",
        "      messages = agent_rules + memory\n",
        "\n",
        "      response = completion(\n",
        "          model=\"openai/gpt-4o\",\n",
        "          messages=messages,\n",
        "          tools=tools,\n",
        "          max_tokens=1024\n",
        "      )\n",
        "\n",
        "      if response.choices[0].message.tool_calls:\n",
        "          tool = response.choices[0].message.tool_calls[0]\n",
        "          tool_name = tool.function.name\n",
        "          tool_args = json.loads(tool.function.arguments)\n",
        "\n",
        "          action = {\n",
        "              \"tool_name\": tool_name,\n",
        "              \"args\": tool_args\n",
        "          }\n",
        "          print(f\"Iteration {iterations}: LLM Action output {action}\")\n",
        "\n",
        "          if tool_name == \"terminate\":\n",
        "              print(f\"Termination message: {tool_args['message']}\")\n",
        "              break\n",
        "          elif tool_name in tool_functions:\n",
        "\n",
        "              try:\n",
        "                  result = {\"result\": tool_functions[tool_name](**tool_args)}\n",
        "              except Exception as e:\n",
        "                  result = {\"error\":f\"Error executing {tool_name}: {str(e)}\"}\n",
        "          else:\n",
        "              result = {\"error\": f\"Unknown tool: {tool_name}\"}\n",
        "\n",
        "          print(f\"Executing: {tool_name} with args {tool_args}\")\n",
        "          print(f\"Result: {result}\")\n",
        "          memory.extend([\n",
        "              {\"role\": \"assistant\", \"content\": json.dumps(action)},\n",
        "              {\"role\": \"user\", \"content\": json.dumps(result)}\n",
        "          ])\n",
        "      else:\n",
        "          result = response.choices[0].message.content\n",
        "          print(f\"Response: {result}\")\n",
        "          break\n",
        "      iterations += 1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "user_task()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LDr3Jy3dRtWf",
        "outputId": "3f18243e-5905-43c8-9f5a-32e9a518e653"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What would you like me to do? read the contents of test.txt\n",
            "Iteration 1: LLM Action output {'tool_name': 'list_files', 'args': {}}\n",
            "Executing: list_files with args {}\n",
            "Result: {'result': ['.config', 'test.txt', 'sample_data']}\n",
            "Iteration 2: LLM Action output {'tool_name': 'read_file', 'args': {'file_name': 'test.txt'}}\n",
            "Executing: read_file with args {'file_name': 'test.txt'}\n",
            "Result: {'result': 'Line1\\nLine2\\nLine3\\n'}\n",
            "Iteration 3: LLM Action output {'tool_name': 'terminate', 'args': {'message': 'The content of test.txt is:\\nLine1\\nLine2\\nLine3'}}\n",
            "Termination message: The content of test.txt is:\n",
            "Line1\n",
            "Line2\n",
            "Line3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AZlRWTOpV1Ow"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "# Create and write to the file 'test.txt'\n",
        "# Using \"w\" mode creates the file if it doesn't exist\n",
        "with open(\"test2.txt\", \"w\") as fp:\n",
        "  fp.writelines([\"test2 Line1\\n\", \"test2 Line2\\n\" , \"test3 Line3\\n\"]) # Added newline characters for proper line breaks\n",
        "\n",
        "# Now you can call user_task() or perform other operations that might read this file\n",
        "user_task()"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UCQHeqD0SJfZ",
        "outputId": "9cd6a730-16b7-46a9-84a9-816dfe71e9f3"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What would you like me to do? read all the file contents\n",
            "Iteration 1: LLM Action output {'tool_name': 'list_files', 'args': {}}\n",
            "Executing: list_files with args {}\n",
            "Result: {'result': ['.config', 'test.txt', 'test2.txt', 'sample_data']}\n",
            "Iteration 2: LLM Action output {'tool_name': 'read_file', 'args': {'file_name': 'test.txt'}}\n",
            "Executing: read_file with args {'file_name': 'test.txt'}\n",
            "Result: {'result': 'Line1\\nLine2\\nLine3\\n'}\n",
            "Iteration 3: LLM Action output {'tool_name': 'read_file', 'args': {'file_name': 'test2.txt'}}\n",
            "Executing: read_file with args {'file_name': 'test2.txt'}\n",
            "Result: {'result': 'test2 Line1\\ntest2 Line2\\ntest3 Line3\\n'}\n",
            "Iteration 4: LLM Action output {'tool_name': 'terminate', 'args': {'message': 'Here are the contents of the files:\\n\\n- **test.txt**:\\n  Line1\\n  Line2\\n  Line3\\n\\n- **test2.txt**:\\n  test2 Line1\\n  test2 Line2\\n  test3 Line3\\n\\nIf you need further assistance, feel free to ask!'}}\n",
            "Termination message: Here are the contents of the files:\n",
            "\n",
            "- **test.txt**:\n",
            "  Line1\n",
            "  Line2\n",
            "  Line3\n",
            "\n",
            "- **test2.txt**:\n",
            "  test2 Line1\n",
            "  test2 Line2\n",
            "  test3 Line3\n",
            "\n",
            "If you need further assistance, feel free to ask!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1dBbRepkSAvV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}